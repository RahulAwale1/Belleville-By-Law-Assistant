{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6782373c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soul./Desktop/Rahul/Natural Language Processing/Belleville By-Law Bot/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesseract version from Python: 5.5.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from huggingface_hub import InferenceClient\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "print(\"Tesseract version from Python:\", pytesseract.get_tesseract_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1f0feed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR output folder: data/ocr_json\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path(\"data\")\n",
    "RAW_PDF_DIR = DATA_DIR / \"raw_pdfs\"\n",
    "OCR_JSON_DIR = DATA_DIR / \"ocr_json\"\n",
    "\n",
    "OCR_JSON_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"OCR output folder:\", OCR_JSON_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "888b27c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_pdf_to_json(pdf_path: Path, output_path: Path):\n",
    "    \"\"\"\n",
    "    OCR a scanned PDF into a JSON structure:\n",
    "    {\n",
    "      \"file_name\": \"...\",\n",
    "      \"pages\": [\n",
    "        {\"page_number\": 1, \"text\": \"...\"},\n",
    "        {\"page_number\": 2, \"text\": \"...\"},\n",
    "        ...\n",
    "      ]\n",
    "    }\n",
    "    \"\"\"\n",
    "    print(f\"Starting OCR for: {pdf_path.name}\")\n",
    "    \n",
    "    # Convert all pages to images\n",
    "    pages = convert_from_path(str(pdf_path))\n",
    "    print(f\"Total pages: {len(pages)}\")\n",
    "    \n",
    "    ocr_pages = []\n",
    "    \n",
    "    for i, img in enumerate(pages, start=1):\n",
    "        print(f\"  - OCR on page {i}...\")\n",
    "        text = pytesseract.image_to_string(img, lang=\"eng\")\n",
    "        ocr_pages.append({\n",
    "            \"page_number\": i,\n",
    "            \"text\": text\n",
    "        })\n",
    "    \n",
    "    data = {\n",
    "        \"file_name\": pdf_path.name,\n",
    "        \"pages\": ocr_pages\n",
    "    }\n",
    "    \n",
    "    # Save to JSON\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"OCR complete! Saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74776ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ocr_pdf_to_json(pdf_path: Path, output_path: Path):\n",
    "#     \"\"\"\n",
    "#     OCR a scanned PDF into a JSON structure:\n",
    "#       { file_name, pages: [{page_number, text, error?}] }\n",
    "#     \"\"\"\n",
    "#     print(f\"Starting OCR for: {pdf_path.name}\")\n",
    "\n",
    "#     # Higher DPI for clearer images\n",
    "#     pages = convert_from_path(str(pdf_path), dpi=300)\n",
    "#     print(f\"Total pages: {len(pages)}\")\n",
    "\n",
    "#     ocr_pages = []\n",
    "\n",
    "#     for i, img in enumerate(pages, start=1):\n",
    "#         print(f\"  - OCR on page {i}...\")\n",
    "#         try:\n",
    "#             # PSM 6 = assume a block of text; tweak if layout differs\n",
    "#             text = pytesseract.image_to_string(img, lang=\"eng\", config=\"--psm 6\")\n",
    "#             ocr_pages.append({\n",
    "#                 \"page_number\": i,\n",
    "#                 \"text\": text  # raw text already stored\n",
    "#             })\n",
    "#         except Exception as e:\n",
    "#             print(f\"    OCR error on page {i}: {e}\")\n",
    "#             ocr_pages.append({\n",
    "#                 \"page_number\": i,\n",
    "#                 \"text\": \"\",\n",
    "#                 \"error\": str(e)  # keep per-page error info\n",
    "#             })\n",
    "\n",
    "#     data = {\n",
    "#         \"file_name\": pdf_path.name,\n",
    "#         \"pages\": ocr_pages\n",
    "#     }\n",
    "\n",
    "#     with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "#         json.dump(data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "#     print(f\"OCR complete! Saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c80c9bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping (already exists): 2025_Fees___Charges_-_BL_2024-201.json\n",
      "Skipping (already exists): BL_2001-129_A_Bylaw_Respecting_Streets_and_Driveway_Controls.json\n",
      "Skipping (already exists): BL_0098-175_A_Bylaw_for_Establishing_Waste_Collection_and_Fees.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Just to be sure these are defined\n",
    "DATA_DIR = Path(\"data\")\n",
    "RAW_PDF_DIR = DATA_DIR / \"raw_pdfs\"\n",
    "OCR_JSON_DIR = DATA_DIR / \"ocr_json\"\n",
    "OCR_JSON_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for pdf_path in RAW_PDF_DIR.glob(\"*.pdf\"):\n",
    "    # Create a cleaner JSON file name from the PDF name\n",
    "    output_name = pdf_path.stem.replace(\" \", \"_\") + \".json\"\n",
    "    output_path = OCR_JSON_DIR / output_name\n",
    "    \n",
    "    # Skip if we already have OCR for this file\n",
    "    if output_path.exists():\n",
    "        print(f\"Skipping (already exists): {output_path.name}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nProcessing PDF: {pdf_path.name}\")\n",
    "    ocr_pdf_to_json(pdf_path, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa014f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR JSON directory: data/ocr_json\n",
      "Chunks will be saved to: data/bylaw_chunks.json\n"
     ]
    }
   ],
   "source": [
    "OCR_JSON_DIR = DATA_DIR / \"ocr_json\"\n",
    "CHUNKS_JSON_PATH = DATA_DIR / \"bylaw_chunks.json\"\n",
    "\n",
    "print(\"OCR JSON directory:\", OCR_JSON_DIR)\n",
    "print(\"Chunks will be saved to:\", CHUNKS_JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73ba2af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 OCR JSON files.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_ocr_json_files(ocr_dir: Path):\n",
    "    docs = []\n",
    "    for json_path in ocr_dir.glob(\"*.json\"):\n",
    "        with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        docs.append(data)\n",
    "    print(f\"Loaded {len(docs)} OCR JSON files.\")\n",
    "    return docs\n",
    "\n",
    "ocr_docs = load_ocr_json_files(OCR_JSON_DIR)\n",
    "len(ocr_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb505757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    # Replace newlines with spaces\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    # Collapse multiple spaces into one\n",
    "    text = \" \".join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39fb1065",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def iter_page_chunks_from_document(doc, chunk_size=800, overlap=200):\n",
    "    \"\"\"\n",
    "    doc: dict loaded from one OCR JSON ({file_name, pages: [...]})\n",
    "    Yields small chunks per page.\n",
    "    \"\"\"\n",
    "    file_name = doc[\"file_name\"]\n",
    "    bylaw_name = Path(file_name).stem.replace(\" \", \"_\")\n",
    "\n",
    "    for page in doc[\"pages\"]:\n",
    "        page_num = page[\"page_number\"]\n",
    "        page_text = clean_text(page[\"text\"])\n",
    "\n",
    "        if not page_text:\n",
    "            continue  # skip empty pages\n",
    "\n",
    "        text_len = len(page_text)\n",
    "        if text_len <= chunk_size:\n",
    "            # Just one chunk for this page\n",
    "            yield {\n",
    "                \"id\": f\"{bylaw_name}_p{page_num}_chunk_0\",\n",
    "                \"file_name\": file_name,\n",
    "                \"bylaw_name\": bylaw_name,\n",
    "                \"page_number\": page_num,\n",
    "                \"text\": page_text,\n",
    "            }\n",
    "        else:\n",
    "            # Split long page into multiple chunks\n",
    "            start = 0\n",
    "            chunk_id = 0\n",
    "\n",
    "            # Safety: make sure chunk_size > overlap so we don't loop forever\n",
    "            if overlap >= chunk_size:\n",
    "                raise ValueError(\"overlap must be smaller than chunk_size\")\n",
    "\n",
    "            while start < text_len:\n",
    "                end = min(start + chunk_size, text_len)\n",
    "                chunk_text = page_text[start:end]\n",
    "\n",
    "                yield {\n",
    "                    \"id\": f\"{bylaw_name}_p{page_num}_chunk_{chunk_id}\",\n",
    "                    \"file_name\": file_name,\n",
    "                    \"bylaw_name\": bylaw_name,\n",
    "                    \"page_number\": page_num,\n",
    "                    \"text\": chunk_text,\n",
    "                }\n",
    "\n",
    "                chunk_id += 1\n",
    "                if end == text_len:\n",
    "                    break  # reached end of page text\n",
    "                start = end - overlap  # move with overlap and continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c6747d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 368 chunks\n",
      "Saved chunks to data/bylaw_chunks.json\n"
     ]
    }
   ],
   "source": [
    "# Build and save chunks from OCR documents\n",
    "chunks = []\n",
    "for doc in ocr_docs:\n",
    "    chunks.extend(iter_page_chunks_from_document(doc, chunk_size=800, overlap=200))\n",
    "\n",
    "print(f\"Generated {len(chunks)} chunks\")\n",
    "CHUNKS_JSON_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(CHUNKS_JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(chunks, f, ensure_ascii=False, indent=2)\n",
    "print(f\"Saved chunks to {CHUNKS_JSON_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f168e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks loaded: 368\n",
      "Example keys: dict_keys(['id', 'file_name', 'bylaw_name', 'page_number', 'text'])\n",
      "Sample text: THE CORPORATION OF THE CITY OF BELLEVILLE BY-LAW NUMBER 2001-129 A BY-LAW RESPECTING STREETS AND DRIVEWAY CONTROLS WHEREAS Section 308 of the Municipal Act R.S.O. 1990, c. M45, as amended provides tha ...\n"
     ]
    }
   ],
   "source": [
    "with open(CHUNKS_JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks = json.load(f)\n",
    "\n",
    "print(\"Number of chunks loaded:\", len(chunks))\n",
    "print(\"Example keys:\", chunks[0].keys())\n",
    "print(\"Sample text:\", chunks[0][\"text\"][:200], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e86d117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded embedding model: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_MODEL_NAME = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "embed_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "print(\"Loaded embedding model:\", EMBEDDING_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad5c59a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total texts to embed: 368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 12/12 [00:01<00:00,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape before cast: (368, 384) float32\n",
      "Embeddings ready. Shape: (368, 384) float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract texts from chunks\n",
    "texts = [c[\"text\"] for c in chunks]\n",
    "print(\"Total texts to embed:\", len(texts))\n",
    "\n",
    "# Create embeddings\n",
    "embeddings = embed_model.encode(\n",
    "    texts,\n",
    "    show_progress_bar=True,\n",
    "    convert_to_numpy=True\n",
    ")\n",
    "\n",
    "print(\"Embeddings shape before cast:\", embeddings.shape, embeddings.dtype)\n",
    "\n",
    "# FAISS prefers float32\n",
    "embeddings = embeddings.astype(\"float32\")\n",
    "\n",
    "# Normalize for cosine similarity\n",
    "faiss.normalize_L2(embeddings)\n",
    "\n",
    "print(\"Embeddings ready. Shape:\", embeddings.shape, embeddings.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb5f8942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index size: 368\n"
     ]
    }
   ],
   "source": [
    "VECTOR_DIM = embeddings.shape[1]\n",
    "index = faiss.IndexFlatIP(VECTOR_DIM)  # IP = inner product\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"FAISS index size:\", index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71dad303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved FAISS index to: data/bylaw_faiss.index\n",
      "Saved metadata to: data/bylaw_metadata.json\n"
     ]
    }
   ],
   "source": [
    "INDEX_PATH = DATA_DIR / \"bylaw_faiss.index\"\n",
    "METADATA_PATH = DATA_DIR / \"bylaw_metadata.json\"\n",
    "\n",
    "# Save FAISS index\n",
    "faiss.write_index(index, str(INDEX_PATH))\n",
    "print(\"Saved FAISS index to:\", INDEX_PATH)\n",
    "\n",
    "# Build & save metadata (everything except embeddings)\n",
    "metadata = [\n",
    "    {\n",
    "        \"id\": c[\"id\"],\n",
    "        \"file_name\": c[\"file_name\"],\n",
    "        \"bylaw_name\": c.get(\"bylaw_name\"),\n",
    "        \"page_number\": c.get(\"page_number\"),\n",
    "        \"text\": c[\"text\"],\n",
    "    }\n",
    "    for c in chunks\n",
    "]\n",
    "\n",
    "with open(METADATA_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Saved metadata to:\", METADATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a2488f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = faiss.read_index(str(INDEX_PATH))\n",
    "\n",
    "with open(METADATA_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3060ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_top_k(query: str, k: int = 5):\n",
    "    # 1. Embed the query\n",
    "    q_emb = embed_model.encode([query], convert_to_numpy=True).astype(\"float32\")\n",
    "    faiss.normalize_L2(q_emb)\n",
    "\n",
    "    # 2. Search FAISS index\n",
    "    D, I = index.search(q_emb, k)\n",
    "    \n",
    "    # 3. Collect results\n",
    "    results = []\n",
    "    for score, idx in zip(D[0], I[0]):\n",
    "        if idx == -1:\n",
    "            continue\n",
    "        chunk_info = metadata[idx]\n",
    "        results.append({\n",
    "            \"score\": float(score),\n",
    "            \"id\": chunk_info[\"id\"],\n",
    "            \"file_name\": chunk_info[\"file_name\"],\n",
    "            \"bylaw_name\": chunk_info.get(\"bylaw_name\"),\n",
    "            \"page_number\": chunk_info.get(\"page_number\"),\n",
    "            \"text\": chunk_info[\"text\"],\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd817383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What fees and charges does the city collect?\n",
      "\n",
      "Result 1:\n",
      "Score: 0.61\n",
      "File: 2025 Fees _ Charges - BL 2024-201.pdf\n",
      "Bylaw: 2025_Fees___Charges_-_BL_2024-201\n",
      "Page: 10\n",
      "Text sample: Change of Ownership — (Property Taxes $25 $30 Change of Occupancy/New Account — Water Bill} New Account $50 $50 Transfer to Taxes — per transaction $20 $20 Payment Transfer (wrong account number) $30 $30 Refund/Overpayment recovery (Tax Bill, Water $30 $35 Bill) Title Search — Property in second yea ...\n",
      "\n",
      "Result 2:\n",
      "Score: 0.509\n",
      "File: 2025 Fees _ Charges - BL 2024-201.pdf\n",
      "Bylaw: 2025_Fees___Charges_-_BL_2024-201\n",
      "Page: 10\n",
      "Text sample: arges are authorized under this by-law. ccept credit card Multi Property Billing List $2 per roll $3 per roll Post Date Cheque Return $15 $15 Corporate Search Recovery Charge $20 $25 Tax Sale costs Actual Recoverable Cost WATER RATES Actual Recoverable Cost Metered First 455 cubic metres $1.99 $2.02 ...\n",
      "\n",
      "Result 3:\n",
      "Score: 0.506\n",
      "File: 2025 Fees _ Charges - BL 2024-201.pdf\n",
      "Bylaw: 2025_Fees___Charges_-_BL_2024-201\n",
      "Page: 1\n",
      "Text sample: THE CORPORATION OF THE CITY OF BELLEVILLE BY-LAW NUMBER 2024-201 A BY-LAW TO PROVIDE FOR FEES AND CHARGES THE COUNCIL OF THE CORPORATION OF THE CITY OF BELLEVILLE ENACTS AS FOLLOWS: WHEREAS Section 391 of The Municipal Act, 2001, permits a municipality to pass By- Laws imposing fees and charges for  ...\n"
     ]
    }
   ],
   "source": [
    "query = \"What fees and charges does the city collect?\"\n",
    "results = retrieve_top_k(query, k=3)\n",
    "\n",
    "print(\"Query:\", query)\n",
    "for i, r in enumerate(results, start=1):\n",
    "    print(f\"\\nResult {i}:\")\n",
    "    print(\"Score:\", round(r[\"score\"], 3))\n",
    "    print(\"File:\", r[\"file_name\"])\n",
    "    print(\"Bylaw:\", r[\"bylaw_name\"])\n",
    "    print(\"Page:\", r[\"page_number\"])\n",
    "    print(\"Text sample:\", r[\"text\"][:300], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d308abb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF token found? True\n"
     ]
    }
   ],
   "source": [
    "HF_TOKEN = os.getenv(\"HUGGINGFACE_API_TOKEN\")\n",
    "print(\"HF token found?\", HF_TOKEN is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97d83b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_LLM_MODEL_NAME = \"HuggingFaceH4/zephyr-7b-beta\"\n",
    "\n",
    "client = InferenceClient(\n",
    "    model=HF_LLM_MODEL_NAME,\n",
    "    token=HF_TOKEN,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9801adbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_context_from_results(results):\n",
    "    \"\"\"\n",
    "    results: list of dicts from retrieve_top_k\n",
    "    Returns: a single string with sources separated by --- markers.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    for r in results:\n",
    "        header = f\"[{r.get('bylaw_name')} | page {r.get('page_number')} | {r.get('file_name')}]\"\n",
    "        parts.append(header + \"\\n\" + r[\"text\"])\n",
    "    return \"\\n\\n---\\n\\n\".join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aac96fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "OLLAMA_MODEL_NAME = \"llama3\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e88511d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_llm_with_context(question: str, context: str, max_new_tokens: int = 300) -> str:\n",
    "    system_prompt = (\n",
    "        \"You are an assistant that answers questions about City of Belleville by-laws.\\n\"\n",
    "        \"Use ONLY the information in the provided CONTEXT.\\n\"\n",
    "        \"If the answer is not clearly in the context, say you are not sure and suggest \"\n",
    "        \"contacting the City of Belleville for confirmation.\\n\\n\"\n",
    "        \"Format your answer as:\\n\"\n",
    "        \"- First, a short 1–2 sentence summary in plain language.\\n\"\n",
    "        \"- Then, a bullet list focusing ONLY on fees or dollar amounts relevant to the question.\\n\"\n",
    "        \"- Each bullet must be of the form: '<item or waste type>: $<amount> (short description if needed)'.\\n\"\n",
    "        \"- Do NOT include operational rules (like number of lifts, tag requirements, schedule rules) in the bullet list;\\n\"\n",
    "        \"  those can be mentioned in the summary if important.\\n\"\n",
    "        \"- Do NOT leave any bullet unfinished. Do NOT end the answer with a hanging '-' or incomplete sentence.\\n\"\n",
    "        \"Do NOT invent information that is not supported by the context.\\n\"\n",
    "        \"Do NOT ask or answer extra questions. Just answer the user's question.\\n\"  \n",
    "    )\n",
    "\n",
    "    user_message = (\n",
    "        f\"Here is the context from Belleville by-laws:\\n\\n\"\n",
    "        f\"{context}\\n\\n\"\n",
    "        f\"Based ONLY on the context above, answer this question clearly and concisely:\\n\"\n",
    "        f\"{question}\"\n",
    "    )\n",
    "\n",
    "    # response = client.chat_completion(\n",
    "    #     model=HF_LLM_MODEL_NAME,\n",
    "    #     messages=[\n",
    "    #         {\"role\": \"system\", \"content\": system_prompt},\n",
    "    #         {\"role\": \"user\", \"content\": user_message},\n",
    "    #     ],\n",
    "    #     max_tokens=max_new_tokens,\n",
    "    #     temperature=0.2,\n",
    "    # )\n",
    "\n",
    "    response = ollama.chat(\n",
    "        model = \"llama3\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_message},\n",
    "        ],\n",
    "        options={\n",
    "            \"num_predict\": max_new_tokens,\n",
    "            \"temperature\": 0.2,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # msg = response.choices[0].message\n",
    "    content = response[\"message\"][\"content\"]\n",
    "    # content = msg[\"content\"] if isinstance(msg, dict) else msg.content\n",
    "    return content.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7bc7036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_question_with_rag(question: str, k: int = 5):\n",
    "    q_lower = question.lower().strip()\n",
    "\n",
    "    # 1. Handle greetings / capability questions explicitly\n",
    "    greeting_phrases = [\n",
    "        \"hello\", \"hi\", \"hey\",\n",
    "        \"what can you do\", \"who are you\",\n",
    "        \"help\", \"how can you help me\",\n",
    "    ]\n",
    "\n",
    "    if any(p in q_lower for p in greeting_phrases):\n",
    "        intro_answer = (\n",
    "            \"Hi! I’m the Belleville By-Law Assistant.\\n\\n\"\n",
    "            \"- I can help you understand City of Belleville by-laws in plain language.\\n\"\n",
    "            \"- You can ask about things like parking rules, noise restrictions, property standards,\\n\"\n",
    "            \"  fees and charges, animals/pets, streets and driveways, and other municipal rules.\\n\"\n",
    "            \"- I’ll look up the relevant by-law sections and summarize them for you, and I’ll tell you\\n\"\n",
    "            \"  which by-law and page the information comes from.\\n\\n\"\n",
    "            \"Try asking something like:\\n\"\n",
    "            \"- \\\"Can I park on the street overnight in Belleville?\\\"\\n\"\n",
    "            \"- \\\"What are the fees for a change of ownership?\\\"\\n\"\n",
    "            \"- \\\"Are there any noise restrictions at night?\\\"\"\n",
    "        )\n",
    "        return {\n",
    "            \"answer\": intro_answer,\n",
    "            \"sources\": [],\n",
    "        }\n",
    "\n",
    "    # 2. Normal RAG flow: retrieve top-k relevant chunks\n",
    "    results = retrieve_top_k(question, k=k)\n",
    "    if not results:\n",
    "        return {\n",
    "            \"answer\": (\n",
    "                \"I couldn’t find any relevant sections in the by-laws for that question. \"\n",
    "                \"Try asking specifically about parking, noise, fees, property standards, \"\n",
    "                \"streets/driveways, or other Belleville by-laws.\"\n",
    "            ),\n",
    "            \"sources\": [],\n",
    "        }\n",
    "\n",
    "    # Check top similarity score to see if this question is relevant at all\n",
    "    top_score = results[0][\"score\"]\n",
    "    if top_score < 0.35:  # you can tune this threshold\n",
    "        return {\n",
    "            \"answer\": (\n",
    "                \"I checked the by-laws I have, but nothing seems clearly related to that question.\\n\\n\"\n",
    "                \"I’m best at answering questions specifically about City of Belleville by-laws — \"\n",
    "                \"for example parking rules, noise by-laws, fees and charges, or property-related rules.\"\n",
    "            ),\n",
    "            \"sources\": [],\n",
    "        }\n",
    "\n",
    "    # 3. Build context string from the retrieved chunks\n",
    "    context = build_context_from_results(results)\n",
    "    \n",
    "    # 4. Get LLM answer (summary + bullet list)\n",
    "    main_answer = call_llm_with_context(question, context)\n",
    "    \n",
    "    # 5. Build structured source info from results\n",
    "    sources = [\n",
    "        {\n",
    "            \"file_name\": r[\"file_name\"],\n",
    "            \"bylaw_name\": r[\"bylaw_name\"],\n",
    "            \"page_number\": r[\"page_number\"],\n",
    "            \"score\": r[\"score\"],\n",
    "        }\n",
    "        for r in results\n",
    "    ]\n",
    "\n",
    "    # 6. Build final source line\n",
    "    seen = set()\n",
    "    source_bits = []\n",
    "    for s in sources:\n",
    "        key = (s[\"bylaw_name\"], s[\"page_number\"])\n",
    "        if key in seen:\n",
    "            continue\n",
    "        seen.add(key)\n",
    "        if s[\"bylaw_name\"] is not None and s[\"page_number\"] is not None:\n",
    "            source_bits.append(f\"{s['bylaw_name']} (page {s['page_number']})\")\n",
    "\n",
    "    if source_bits:\n",
    "        source_line = \"_Source by-laws: \" + \", \".join(source_bits) + \"._\"\n",
    "        full_answer = main_answer + \"\\n\\n\" + source_line\n",
    "    else:\n",
    "        full_answer = main_answer\n",
    "\n",
    "    return {\n",
    "        \"answer\": full_answer,\n",
    "        \"sources\": sources,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "53f1b197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Belleville By-Law Assistant\")\n",
    "    print(\"Type your question about by-laws.\")\n",
    "    print(\"Type 'exit' or 'quit' to stop.\\n\")\n",
    "\n",
    "    while True:\n",
    "        question = input(\"You: \").strip()\n",
    "        if question.lower() in (\"exit\", \"quit\"):\n",
    "            print(\"Bot: Goodbye!\")\n",
    "            break\n",
    "\n",
    "        if not question:\n",
    "            continue  # skip empty input\n",
    "\n",
    "        res = answer_question_with_rag(question, k=5)\n",
    "        print(\"\\nYou:\", question)\n",
    "        print(\"\\nBot:\", res[\"answer\"])\n",
    "        print(\"\\nSources:\")\n",
    "        for s in res[\"sources\"]:\n",
    "            print(\n",
    "                f\"- {s['file_name']} | {s['bylaw_name']} | \"\n",
    "                f\"page {s['page_number']} | score={s['score']:.3f}\"\n",
    "            )\n",
    "        print(\"\\n\" + \"-\" * 60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "015111a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d1ac2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_chat(message, history):\n",
    "    result = answer_question_with_rag(message, k=5)\n",
    "    answer = result[\"answer\"]\n",
    "\n",
    "    # Build a simple sources text block\n",
    "    if result[\"sources\"]:\n",
    "        src_lines = [\"\\n\\n**Sources:**\"]\n",
    "        for s in result[\"sources\"]:\n",
    "            src_lines.append(\n",
    "                f\"- `{s['bylaw_name']}` (page {s['page_number']}, score={s['score']:.3f})\"\n",
    "            )\n",
    "        answer = answer + \"\\n\" + \"\\n\".join(src_lines)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71eb5eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soul./Desktop/Rahul/Natural Language Processing/Belleville By-Law Bot/.venv/lib/python3.12/site-packages/gradio/chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    fn=rag_chat,\n",
    "    title=\"⚖️ Belleville By-Law Assistant\",\n",
    "    description=(\n",
    "        \"Ask questions about City of Belleville by-laws (parking, noise, waste, fees, \"\n",
    "        \"property standards, streets/driveways, etc.).\\n\\n\"\n",
    "        \"I will search the by-laws and summarize the relevant sections for you.\"\n",
    "    ),\n",
    "    examples=[\n",
    "        \"Can I park on the street overnight in Belleville?\",\n",
    "        \"What are the waste collection fees?\",\n",
    "        \"What fees and charges does the city collect?\",\n",
    "        \"Are there any noise restrictions at night?\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
